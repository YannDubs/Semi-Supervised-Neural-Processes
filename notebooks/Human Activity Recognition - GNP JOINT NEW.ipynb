{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition - SSL JOINT Consistency\n",
    "\n",
    "Last Update : 31 July 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8\n",
    "# Nota Bene : notebooks don't deallocate GPU memory\n",
    "IS_FORCE_CPU = False # can also be set in the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/conv\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "import os\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skssl.transformers.neuralproc.datasplit import CntxtTrgtGetter, GetRandomIndcs, get_all_indcs\n",
    "from utils.data.tsdata import get_timeseries_dataset, SparseMultiTimeSeriesDataset\n",
    "\n",
    "get_cntxt_trgt_test = CntxtTrgtGetter(contexts_getter=GetRandomIndcs(min_n_indcs=0.1, max_n_indcs=0.5),\n",
    "                                     targets_getter=get_all_indcs,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt_feat = CntxtTrgtGetter(contexts_getter=get_all_indcs,\n",
    "                                     targets_getter=get_all_indcs,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt = CntxtTrgtGetter(contexts_getter=GetRandomIndcs(min_n_indcs=0.01, max_n_indcs=0.99),\n",
    "                                 targets_getter=GetRandomIndcs(min_n_indcs=0.5, max_n_indcs=0.99),\n",
    "                                 is_add_cntxts_to_trgts=False)  # don't context points to tagrtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_both = get_timeseries_dataset(\"har\")(split=\"both\")\n",
    "\n",
    "def cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=False):\n",
    "    def mycollate(batch):\n",
    "        min_length = min([v.size(0) for b in batch for k,v in b[0].items() if \"X\" in k])\n",
    "        # chose first min_legth of each (assumes that randomized)\n",
    "        \n",
    "        batch = [({k:v[:min_length, ...] for k,v in b[0].items()}, b[1]) for b in batch]        \n",
    "        collated = torch.utils.data.dataloader.default_collate(batch)\n",
    "        \n",
    "        X = collated[0][\"X\"]\n",
    "        y = collated[0][\"y\"]\n",
    "        \n",
    "        if is_repeat_batch:\n",
    "            \n",
    "            X = torch.cat([X,X], dim=0)\n",
    "            y = torch.cat([y,y], dim=0)\n",
    "            collated[1] = torch.cat([collated[1], collated[1]], dim=0) # targets\n",
    "        \n",
    "        collated[0][\"X\"], collated[0][\"y\"], collated[0][\"X_trgt\"], collated[0][\"y_trgt\"] = get_cntxt_trgt(X, y)\n",
    "        \n",
    "        return collated\n",
    "    return mycollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 1  # 1D spatial input (although actually 2 but the first is for sparse channels)\n",
    "Y_DIM = data_both.data.shape[-1] # multiple channels\n",
    "N_TARGETS = len(np.unique(data_both.targets))\n",
    "\n",
    "sampling_percentages = [0.05, 0.1, 0.3, 0.5, 0.7, 1]\n",
    "label_percentages = [N_TARGETS, N_TARGETS*2, 0.01, 0.05, 0.1, 0.3, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from skssl.transformers import GlobalNeuralProcess, NeuralProcessLoss, AttentiveNeuralProcess, NeuralProcessSSLLoss\n",
    "from skssl.utils.helpers import rescale_range\n",
    "from skssl.predefined import UnetCNN, CNN, MLP, SparseSetConv, SetConv, MlpRBF, GaussianRBF, BatchSparseSetConv\n",
    "from skssl.transformers.neuralproc.datasplit import precomputed_cntxt_trgt_split\n",
    "from utils.helpers import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "models = {}\n",
    "\n",
    "min_std=5e-3\n",
    "\n",
    "unet = partial(UnetCNN,\n",
    "               Conv=torch.nn.Conv1d,\n",
    "               Pool=torch.nn.MaxPool1d,\n",
    "               upsample_mode=\"linear\",\n",
    "               n_layers=18,\n",
    "               is_double_conv=True,\n",
    "               is_depth_separable=True,\n",
    "               Normalization=torch.nn.BatchNorm1d,\n",
    "               is_chan_last=True,\n",
    "               bottleneck=None,\n",
    "               kernel_size=7,\n",
    "               max_nchannels=256,\n",
    "              is_force_same_bottleneck=True,\n",
    "               _is_summary=True,\n",
    "              )\n",
    "\n",
    "kwargs = dict(x_dim=X_DIM, \n",
    "              y_dim=Y_DIM,\n",
    "              min_std=min_std,\n",
    "                n_tmp_queries=128,\n",
    "                r_dim=64,\n",
    "              keys_to_tmp_attn=partial(SetConv, RadialBasisFunc=GaussianRBF),\n",
    "              TmpSelfAttn=unet,\n",
    "              tmp_to_queries_attn=partial(SetConv, RadialBasisFunc=GaussianRBF),\n",
    "              is_skip_tmp=False,\n",
    "              is_use_x=False,\n",
    "              get_cntxt_trgt=precomputed_cntxt_trgt_split,\n",
    "              is_encode_xy=False,\n",
    "             Classifier=partial(MLP, input_size=256+Y_DIM*4, output_size=N_TARGETS, \n",
    "                                dropout=0., hidden_size=128, n_hidden_layers=3, is_res=True))\n",
    "\n",
    "models[\"ssl_classifier_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs)\n",
    "\n",
    "kwargs_bis = deepcopy(kwargs)\n",
    "kwargs_bis[\"Classifier\"] = None\n",
    "\n",
    "models[\"transformer_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_classifier_gnp_large_shared_bottleneck - N Param: 1078238\n",
      "transformer_gnp_large_shared_bottleneck - N Param: 1006936\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import count_parameters\n",
    "for k,v in models.items():\n",
    "    print(k, \"- N Param:\", count_parameters(v()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_(models, sampling_percentages):\n",
    "    # ALREADY INITALIZE TO BE ABLE TO LOAD\n",
    "    models[\"ssl_classifier_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs)()\n",
    "\n",
    "    kwargs_bis = deepcopy(kwargs)\n",
    "    kwargs_bis[\"Classifier\"] = None\n",
    "\n",
    "    models[\"transformer_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs_bis)()\n",
    "\n",
    "    # load all transformers\n",
    "    loaded_models = {}\n",
    "    for sampling_perc in sampling_percentages:\n",
    "        for k, m in models.items():\n",
    "            if \"transformer\" not in k:\n",
    "                continue\n",
    "\n",
    "            out = train_models_({\"{}%har\".format(int(sampling_perc*100)): \n",
    "                                                (None, None)}, \n",
    "                                  {k :m },\n",
    "                                   chckpnt_dirname=chckpnt_dirname_old,\n",
    "                                seed=None,\n",
    "                                   is_retrain=False)\n",
    "\n",
    "            pretrained_model = out[list(out.keys())[0]].module_\n",
    "            model_dict = models[k.replace(\"transformer\", \"ssl_classifier\")].state_dict()\n",
    "            model_dict.update(pretrained_model.state_dict())\n",
    "            models[k.replace(\"transformer\", \"ssl_classifier\")].load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntbks_helpers import train_models_\n",
    "from skorch.dataset import CVSplit\n",
    "from utils.data.ssldata import get_train_dev_test_ssl\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 100 \n",
    "BATCH_SIZE = 32\n",
    "IS_RETRAIN = False # if false load precomputed\n",
    "chckpnt_dirname_old=\"results/challenge/har/\"\n",
    "chckpnt_dirname=\"results/challenge/har_new/\"\n",
    "\n",
    "from skssl.utils.helpers import HyperparameterInterpolator\n",
    "\n",
    "n_steps_per_epoch = len(data_both)//BATCH_SIZE\n",
    "get_lambda_clf=HyperparameterInterpolator(1, 10, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "7352\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug best epoch: 20 val_loss: 0.27427897649091754\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "7352\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug best epoch: 8 val_loss: 0.18001823478688497\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "7352\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug best epoch: 4 val_loss: 0.20004334868841103\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=False)\n",
    "            print(len(data_train))\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_noaug\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.934736</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.93417</td>\n",
       "      <td>0.935528</td>\n",
       "      <td>0.935697</td>\n",
       "      <td>0.935867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.934736   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.001674   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.932813   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        25%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.93417   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.935528   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.935697   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.935867  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "12504\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.1426355674544359\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "12504\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.14788568104815167\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "12504\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.16581127908135174\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "            print(len(data_train))\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.947065</td>\n",
       "      <td>0.94961</td>\n",
       "      <td>0.952155</td>\n",
       "      <td>0.95436</td>\n",
       "      <td>0.956566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.951929   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.004755   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.947065   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        25%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.94961   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.952155   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        75%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.95436   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.956566  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Neg Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons best epoch: 1 val_loss: 0.16748589485590443\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons best epoch: 2 val_loss: 0.1616656260042232\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons best epoch: 1 val_loss: 0.17687109902547107\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):  \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nonegcons\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 1,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.949327</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>0.947743</td>\n",
       "      <td>0.948252</td>\n",
       "      <td>0.948761</td>\n",
       "      <td>0.950119</td>\n",
       "      <td>0.951476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.949327   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        std   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.00193   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.947743   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.948252   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.948761   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.950119   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.951476  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent best epoch: 1 val_loss: 0.15668519885409757\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent best epoch: 1 val_loss: 0.1925992108135756\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent best epoch: 1 val_loss: 0.20008442545083252\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_noent\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 1.,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_noent</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.945368</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.943332</td>\n",
       "      <td>0.94469</td>\n",
       "      <td>0.946047</td>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.946725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.945368   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.001796   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.943332   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        25%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.94469   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.946047   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.946386   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.946725  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup best epoch: 1 val_loss: 0.15670357431684714\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup best epoch: 1 val_loss: 0.16049837192358557\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup best epoch: 1 val_loss: 0.14915962489451892\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nounsup\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 0,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.952607</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.948761</td>\n",
       "      <td>0.950797</td>\n",
       "      <td>0.952833</td>\n",
       "      <td>0.95453</td>\n",
       "      <td>0.956227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.952607   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.003738   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.948761   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.950797   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.952833   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        75%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.95453   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.956227  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SSL Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.4417\u001b[0m       \u001b[32m0.9179\u001b[0m        \u001b[35m0.2222\u001b[0m     +  81.2856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.2254\u001b[0m       \u001b[32m0.9365\u001b[0m        \u001b[35m0.2180\u001b[0m     +  81.4742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        0.2322       0.9175        0.3426        79.5648\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        \u001b[36m0.1684\u001b[0m       0.9233        0.4265        80.1608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        0.1774       0.9199        0.3272        78.5329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        0.3132       0.9342        \u001b[35m0.1853\u001b[0m        80.5541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.0831\u001b[0m       0.9332        0.3177        80.3634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.2907       \u001b[32m0.9416\u001b[0m        0.2979     +  79.2275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        \u001b[36m0.0259\u001b[0m       0.9410        0.2815        80.1413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.1804       0.9332        0.4104        80.9457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        \u001b[36m0.0036\u001b[0m       0.9403        0.4545        52.6508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12       \u001b[36m-0.0321\u001b[0m       0.9379        0.4363        53.5234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.1342       0.9359        0.4372        56.1822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14       -0.0294       0.9355        0.4397        55.7584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.6576       \u001b[32m0.9535\u001b[0m        0.2205     +  56.1551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.1499       \u001b[32m0.9610\u001b[0m        \u001b[35m0.1699\u001b[0m     +  59.7283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.0380       0.9484        0.3082        79.3126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.1501       0.9508        0.2351        80.6645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.2064       0.9545        0.2387        81.4052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20       -0.0122       0.9532        0.2655        79.7867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     21        0.0504       0.9518        0.2843        80.6573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     22        0.0338       0.9505        0.3636        77.3600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     23        1.0224       0.9501        0.2616        79.1576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     24        0.0465       0.9430        0.4965        80.8012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     25        0.3215       0.9562        0.2582        80.0738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     26        0.1287       0.9559        0.2612        81.2201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     27        0.6983       0.9539        0.2628        79.9133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     28        0.0938       0.9471        0.3304        78.7809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     29        0.1093       0.9359        0.3704        80.5431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     30        0.1500       0.9393        0.3903        79.6116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly best epoch: 16 val_loss: 0.1699327095346933\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.4851\u001b[0m       \u001b[32m0.9386\u001b[0m        \u001b[35m0.1679\u001b[0m     +  80.9580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.3073\u001b[0m       \u001b[32m0.9440\u001b[0m        0.1987     +  80.1387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.2316\u001b[0m       0.9365        0.2588        58.7042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        \u001b[36m0.0852\u001b[0m       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1664\u001b[0m     +  55.8342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5       \u001b[36m-0.0229\u001b[0m       0.9481        0.2144        54.8578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        0.3217       0.9376        0.2315        56.0347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        0.4279       \u001b[32m0.9596\u001b[0m        \u001b[35m0.1598\u001b[0m     +  55.8229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.1866       0.9464        0.2456        53.9710\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        0.1498       0.9505        0.1924        55.9046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10       -0.0129       0.9511        0.3378        54.3489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11       -0.0095       0.9539        0.2092        53.2954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.0055       0.9454        0.3480        52.4598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.8728       0.9423        0.2934        53.5952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.3215       0.9488        0.3230        53.4625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.0818       0.9522        0.2538        55.1835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.0504       0.9460        0.3109        55.1996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.1241       0.9321        0.3091        54.7527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.0342       0.9427        0.2807        55.6552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.1476       0.9539        0.2480        55.3252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20        0.0428       0.9365        0.4001        54.9211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     21        0.4555       0.9498        0.2313        55.4418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=507), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly best epoch: 7 val_loss: 0.15977995857611565\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_sslonly\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=True,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                               seed=None,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.960299</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.95962</td>\n",
       "      <td>0.959959</td>\n",
       "      <td>0.960299</td>\n",
       "      <td>0.960638</td>\n",
       "      <td>0.960977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             2.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.960299   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        std   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.00096   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        min   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.95962   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.959959   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.960299   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.960638   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.960977  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUp Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m1.7205\u001b[0m       \u001b[32m0.9420\u001b[0m        \u001b[35m0.1594\u001b[0m     +  17.2882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.5487\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.1119\u001b[0m     +  16.9470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.5105\u001b[0m       0.9352        0.2376        17.3083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        0.5581       0.9491        0.1546        17.1064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        \u001b[36m0.3509\u001b[0m       0.9427        0.2236        17.4736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        \u001b[36m0.2475\u001b[0m       0.9447        0.2271        17.4863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.1133\u001b[0m       0.9450        0.2571        17.4543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.1590       0.9253        0.4345        17.1062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        0.5702       0.9440        0.1866        16.9203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.2507       0.9477        0.1835        17.1786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.3096       0.9403        0.2373        17.7751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.4494       0.9498        0.2714        17.6188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.1617       0.9498        0.2671        17.6785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.1607       \u001b[32m0.9528\u001b[0m        0.2394     +  17.1189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        \u001b[36m0.1072\u001b[0m       0.9477        0.3096        17.5728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.1534       0.9318        0.3020        16.9922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.7972       \u001b[32m0.9583\u001b[0m        0.1365     +  17.7162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.1902       0.9498        0.1947        17.5865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.2807       0.9379        0.2225        17.4033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20        0.2163       0.9420        0.3061        17.7230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     21        0.3057       0.9233        0.5980        17.6642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     22        1.0109       0.9284        0.3515        17.3006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     23        0.6165       0.9352        0.3549        17.6430\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     24        0.2033       0.9355        0.3523        17.5848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     25        0.1782       0.9382        0.3394        16.6851\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     26        0.1281       0.9345        0.3433        17.4630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     27        \u001b[36m0.0849\u001b[0m       0.9437        0.2857        17.5177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     28        0.1738       0.9413        0.3156        17.4152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     29        0.8849       0.9542        0.3972        17.3130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     30        2.1433       0.9376        0.4193        17.3452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     31        0.2265       0.9365        0.3928        17.4978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly best epoch: 2 val_loss: 0.11194615579274406\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m2.0968\u001b[0m       \u001b[32m0.9393\u001b[0m        \u001b[35m0.1887\u001b[0m     +  17.6020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.5852\u001b[0m       0.9355        0.1984        17.3802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.3013\u001b[0m       0.9386        0.2158        17.3227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        0.3896       \u001b[32m0.9549\u001b[0m        \u001b[35m0.1170\u001b[0m     +  16.8216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        0.5356       0.9535        0.1525        17.2007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        0.4578       0.9539        0.1842        17.3159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.1223\u001b[0m       \u001b[32m0.9593\u001b[0m        0.1819     +  17.3260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.4661       \u001b[32m0.9661\u001b[0m        0.1204     +  17.0947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        0.9383       0.9498        0.1822        16.5356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.5322       0.9569        0.1519        17.2610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.2184       0.9617        0.1346        17.2033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.2378       0.9549        0.1781        17.5254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        \u001b[36m0.1151\u001b[0m       0.9600        0.1333        17.7832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.1597       0.9654        0.1217        17.4616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        \u001b[36m0.0777\u001b[0m       0.9603        0.1510        17.4753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.1305       0.9508        0.2105        17.0208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.9957       0.9332        0.3301        16.4667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.6338       0.9501        0.1676        16.9288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.2291       0.9559        0.2176        17.2005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20        0.1676       0.9457        0.2701        16.5841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     21        0.1567       0.9505        0.2601        16.9154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     22        0.1856       0.9488        0.2931        16.0577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly best epoch: 4 val_loss: 0.11700662759186091\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m1.7188\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m0.1610\u001b[0m     +  17.4609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.5189\u001b[0m       \u001b[32m0.9528\u001b[0m        \u001b[35m0.1379\u001b[0m     +  17.0388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.3240\u001b[0m       \u001b[32m0.9593\u001b[0m        0.1583     +  16.5276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        \u001b[36m0.2981\u001b[0m       \u001b[32m0.9596\u001b[0m        \u001b[35m0.1262\u001b[0m     +  16.2472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        0.5236       0.9216        0.3746        16.4081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        \u001b[36m0.1333\u001b[0m       \u001b[32m0.9674\u001b[0m        \u001b[35m0.1170\u001b[0m     +  16.5778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.1246\u001b[0m       0.9664        0.1190        17.4434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.4408       0.9471        0.1968        17.1569\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        0.2640       0.9437        0.2380        17.2770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.1300       0.9562        0.1961        17.2334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        \u001b[36m0.0856\u001b[0m       0.9589        0.2079        17.2196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.1434       0.9610        0.1802        17.3788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.1442       0.9467        0.3021        17.1873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.2874       0.9545        0.1884        16.8735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.5641       0.9491        0.1636        17.6431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.3760       0.9566        0.1812        17.3251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.1470       0.9539        0.2167        17.5550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.0942       0.9576        0.2046        17.5022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.0968       0.9600        0.2575        17.1090\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20        0.1680       0.9494        0.2645        16.5031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly best epoch: 6 val_loss: 0.1170268439825891\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "            \n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = data_train.data[(data_train.targets!=-1).squeeze()]\n",
    "            data_train.targets = data_train.targets[(data_train.targets!=-1).squeeze()]\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_suponly\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=True,\n",
    "                                                    get_lambda_unsup=lambda: 0,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                    seed=None,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.963918</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.958263</td>\n",
       "      <td>0.962165</td>\n",
       "      <td>0.966067</td>\n",
       "      <td>0.966746</td>\n",
       "      <td>0.967424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.963918   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.004945   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.958263   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.962165   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.966067   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.966746   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.967424  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sup Only No Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.2326\u001b[0m       \u001b[32m0.9233\u001b[0m        \u001b[35m0.2089\u001b[0m     +  17.7597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.0824\u001b[0m       \u001b[32m0.9535\u001b[0m        \u001b[35m0.1454\u001b[0m     +  17.5394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.0482\u001b[0m       \u001b[32m0.9610\u001b[0m        \u001b[35m0.1342\u001b[0m     +  17.2043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        0.0490       0.9481        0.1779        17.8247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        \u001b[36m0.0459\u001b[0m       0.9372        0.2108        17.7624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        \u001b[36m0.0389\u001b[0m       0.9477        0.1558        17.2868\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        0.0447       0.9494        0.1633        17.3184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        \u001b[36m0.0306\u001b[0m       0.9562        0.1450        17.1968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        \u001b[36m0.0279\u001b[0m       \u001b[32m0.9647\u001b[0m        \u001b[35m0.1194\u001b[0m     +  17.6493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        \u001b[36m0.0196\u001b[0m       0.9627        0.1326        17.5911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.0343       0.9467        0.2448        17.4581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.0234       0.9488        0.1880        17.5720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.0294       0.9623        0.1638        17.7644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.0358       0.9572        0.1716        17.0836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.0341       0.9457        0.2181        17.5609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.0234       0.9430        0.2331        17.6432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        \u001b[36m0.0189\u001b[0m       0.9369        0.2663        17.6876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.0291       0.9301        0.2348        17.5801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.0196       0.9437        0.2168        17.4684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20        0.0311       0.9348        0.3361        17.4953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     21        0.0246       0.9359        0.2405        17.5650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     22        0.0229       0.9430        0.3039        17.5389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     23        0.0204       0.9379        0.2426        16.9236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla best epoch: 9 val_loss: 0.11944592917293632\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.2482\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m0.1434\u001b[0m     +  16.0712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.0784\u001b[0m       \u001b[32m0.9518\u001b[0m        0.1468     +  15.9407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.0514\u001b[0m       \u001b[32m0.9586\u001b[0m        0.1504     +  16.0849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        \u001b[36m0.0457\u001b[0m       \u001b[32m0.9647\u001b[0m        \u001b[35m0.1242\u001b[0m     +  15.9126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        0.0478       0.9576        0.1478        16.3576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        \u001b[36m0.0439\u001b[0m       0.9634        \u001b[35m0.1037\u001b[0m        15.7396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.0293\u001b[0m       0.9498        0.1807        16.3389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.0361       0.9623        0.1621        16.1349\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        \u001b[36m0.0189\u001b[0m       \u001b[32m0.9667\u001b[0m        0.1342     +  16.2840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.0258       0.9606        0.1274        16.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.0231       0.9600        0.1396        16.2483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.0299       0.9522        0.1935        16.1761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.0309       0.9528        0.2608        16.2893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.0236       0.9617        0.1389        15.9906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.0274       0.9559        0.1984        16.2180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.0240       0.9532        0.1846        16.2448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.0195       0.9603        0.1329        15.8780\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     18        0.0284       0.9606        0.1548        16.3068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     19        0.0225       0.9515        0.2241        15.8676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     20        0.0345       0.9403        0.3249        16.1969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     21        0.0526       0.9620        0.1884        16.2671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     22        0.0358       0.9433        0.2477        15.8537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     23        0.0269       0.9539        0.2722        15.8218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla best epoch: 6 val_loss: 0.1036831834253959\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.2588\u001b[0m       \u001b[32m0.9287\u001b[0m        \u001b[35m0.2280\u001b[0m     +  16.0761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.1147\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m0.1895\u001b[0m     +  16.2848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.0690\u001b[0m       \u001b[32m0.9569\u001b[0m        \u001b[35m0.1292\u001b[0m     +  16.1193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        \u001b[36m0.0460\u001b[0m       0.9481        0.2074        15.8959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        \u001b[36m0.0316\u001b[0m       0.9501        0.2123        16.1078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        0.0544       0.9511        0.1601        16.2500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        0.0344       0.9372        0.2712        17.0520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.0444       0.9525        0.2027        24.5794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        0.0319       0.9518        0.2220        24.6843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.0367       0.9481        0.2474        24.5883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        \u001b[36m0.0231\u001b[0m       0.9474        0.2332        24.8233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.0432       0.9498        0.2309        25.2457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.0297       0.9420        0.2838        24.5041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.0239       0.9403        0.2933        25.1758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        \u001b[36m0.0174\u001b[0m       0.9369        0.3352        24.5751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.0406       0.9471        0.2295        24.6295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        \u001b[36m0.0167\u001b[0m       0.9528        0.2350        24.9286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla best epoch: 3 val_loss: 0.12915067612861947\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = data_train.data[(data_train.targets!=-1).squeeze()]\n",
    "            data_train.targets = data_train.targets[(data_train.targets!=-1).squeeze()]\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_sup_vanilla\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda : 1,\n",
    "                                                    n_max_elements=None,\n",
    "                                                    label_perc=None, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=True,\n",
    "                                                    get_lambda_unsup=lambda: 0,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=True,\n",
    "                                               seed=None,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.962787</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.956905</td>\n",
       "      <td>0.960808</td>\n",
       "      <td>0.96471</td>\n",
       "      <td>0.965728</td>\n",
       "      <td>0.966746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.962787   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.005194   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.956905   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.960808   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        50%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.96471   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.965728   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.966746  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Lambda CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda best epoch: 1 val_loss: 0.16846257951812668\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda best epoch: 1 val_loss: 0.14787215202754517\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda best epoch: 2 val_loss: 0.13356725409915235\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nolambda\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: 1,\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.956566</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.947404</td>\n",
       "      <td>0.953003</td>\n",
       "      <td>0.958602</td>\n",
       "      <td>0.961147</td>\n",
       "      <td>0.963692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.956566   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.008333   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.947404   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.953003   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.958602   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.961147   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.963692  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Label Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale best epoch: 18 val_loss: 0.2315054115376984\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale best epoch: 2 val_loss: 0.18339065070230307\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale best epoch: 1 val_loss: 0.26924419039016584\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nolabscale\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=None, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.953399</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.947743</td>\n",
       "      <td>0.949101</td>\n",
       "      <td>0.950458</td>\n",
       "      <td>0.956227</td>\n",
       "      <td>0.961995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.953399   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.007567   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.947743   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.949101   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.950458   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.956227   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.961995  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Element Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale best epoch: 7 val_loss: 0.1779502336963541\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale best epoch: 7 val_loss: 0.20060293440661897\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale best epoch: 7 val_loss: 0.15404326194903015\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_noelemscale\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=None,\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.949779</td>\n",
       "      <td>0.950967</td>\n",
       "      <td>0.952155</td>\n",
       "      <td>0.952833</td>\n",
       "      <td>0.953512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.951815   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.001889   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.949779   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.950967   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.952155   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.952833   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 10% 100%         0.953512  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale epoch: 7 val_loss: 0.1779502336963541 val_acc: 0.9429928741092637\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale epoch: 7 val_loss: 0.20060293440661897 val_acc: 0.9399389209365456\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale epoch: 7 val_loss: 0.15404326194903015 val_acc: 0.9535120461486257\n"
     ]
    }
   ],
   "source": [
    "for k,t in data_trainers.items(): \n",
    "    for e, h in enumerate(t.history[::-1]):\n",
    "        if h[\"valid_acc_best\"]:\n",
    "            print(k, \"epoch:\", len(t.history)-e, \n",
    "                  \"val_loss:\", h[\"valid_loss\"], \n",
    "                  \"val_acc:\", h[\"valid_acc\"])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck ---\n",
      "\n",
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck best epoch: 2 val_loss: 0.2708716995238013\n",
      "\n",
      "--- Loading har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck ---\n",
      "\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck best epoch: 5 val_loss: 0.1961393239824964\n",
      "\n",
      "--- Loading har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck ---\n",
      "\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck best epoch: 2 val_loss: 0.19988441305480895\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "models[\"ssl_classifier_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs)\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.1]:\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.931795</td>\n",
       "      <td>0.00622</td>\n",
       "      <td>0.925008</td>\n",
       "      <td>0.92908</td>\n",
       "      <td>0.933152</td>\n",
       "      <td>0.935188</td>\n",
       "      <td>0.937224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy            \\\n",
       "                                                              count      mean   \n",
       "models                                     lab data sample                      \n",
       "ssl_classifier_gnp_large_shared_bottleneck 10% 100%             3.0  0.931795   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                std       min   \n",
       "models                                     lab data sample                      \n",
       "ssl_classifier_gnp_large_shared_bottleneck 10% 100%         0.00622  0.925008   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                25%       50%   \n",
       "models                                     lab data sample                      \n",
       "ssl_classifier_gnp_large_shared_bottleneck 10% 100%         0.92908  0.933152   \n",
       "\n",
       "                                                                                \n",
       "                                                                 75%       max  \n",
       "models                                     lab data sample                      \n",
       "ssl_classifier_gnp_large_shared_bottleneck 10% 100%         0.935188  0.937224  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "har100%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck epoch: 2 val_loss: 0.2708716995238013 val_acc: 0.9121140142517815\n",
      "har100%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck epoch: 5 val_loss: 0.1961393239824964 val_acc: 0.9307770614183916\n",
      "har100%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck epoch: 2 val_loss: 0.19988441305480895 val_acc: 0.9270444519850696\n"
     ]
    }
   ],
   "source": [
    "#0.9644 with both supervised and unsupervised with finetuning\n",
    "\n",
    "for k,t in data_trainers.items(): \n",
    "    for e, h in enumerate(t.history[::-1]):\n",
    "        if h[\"valid_acc_best\"]:\n",
    "            print(k, \"epoch:\", len(t.history)-e, \n",
    "                  \"val_loss:\", h[\"valid_loss\"], \n",
    "                  \"val_acc:\", h[\"valid_acc\"])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Sampling Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 5%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "5%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -2.164531707763672\n",
      "\n",
      "--- Loading har5%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har5%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 5 val_loss: 0.6508865955121079\n",
      "\n",
      "--- Loading 10%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "10%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -2.98053588682008\n",
      "\n",
      "--- Loading har10%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har10%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 11 val_loss: 0.37507563022431145\n",
      "\n",
      "--- Loading 30%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "30%har/transformer_gnp_large_shared_bottleneck best epoch: 87 val_loss: -4.5797279249117215\n",
      "\n",
      "--- Loading har30%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har30%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 10 val_loss: 0.23837404603831922\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.1724112945611007\n",
      "\n",
      "--- Loading 70%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "70%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -7.103462460897501\n",
      "\n",
      "--- Loading har70%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har70%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 10 val_loss: 0.0867358241843336\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 32 val_loss: 0.09407840634266076\n",
      "\n",
      "--- Loading 5%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "5%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -2.164531707763672\n",
      "\n",
      "--- Loading har5%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har5%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 0.67058725331976\n",
      "\n",
      "--- Loading 10%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "10%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -2.98053588682008\n",
      "\n",
      "--- Loading har10%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har10%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.3828051966413714\n",
      "\n",
      "--- Loading 30%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "30%har/transformer_gnp_large_shared_bottleneck best epoch: 87 val_loss: -4.5797279249117215\n",
      "\n",
      "--- Loading har30%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har30%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 13 val_loss: 0.22198712692286637\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.13504620766615438\n",
      "\n",
      "--- Loading 70%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "70%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -7.103462460897501\n",
      "\n",
      "--- Loading har70%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har70%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 0.06980159107126703\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.1130930731811886\n",
      "\n",
      "--- Loading 5%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "5%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -2.164531707763672\n",
      "\n",
      "--- Loading har5%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har5%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.6709550162837349\n",
      "\n",
      "--- Loading 10%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "10%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -2.98053588682008\n",
      "\n",
      "--- Loading har10%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har10%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 0.40490604442088257\n",
      "\n",
      "--- Loading 30%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "30%har/transformer_gnp_large_shared_bottleneck best epoch: 87 val_loss: -4.5797279249117215\n",
      "\n",
      "--- Loading har30%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har30%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 10 val_loss: 0.17537192939134383\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.10383275301932965\n",
      "\n",
      "--- Loading 70%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "70%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -7.103462460897501\n",
      "\n",
      "--- Loading har70%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har70%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 0.08426787693863769\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 21 val_loss: 0.09288473132508548\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in sampling_percentages:\n",
    "        for label_perc in [1]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ssl_classifier_gnp_large_shared_bottleneck_finetune</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">100%</th>\n",
       "      <th>10%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.902047</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.901256</td>\n",
       "      <td>0.901765</td>\n",
       "      <td>0.902273</td>\n",
       "      <td>0.902443</td>\n",
       "      <td>0.902613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.976021</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.968782</td>\n",
       "      <td>0.972345</td>\n",
       "      <td>0.975908</td>\n",
       "      <td>0.979640</td>\n",
       "      <td>0.983373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.956905</td>\n",
       "      <td>0.956905</td>\n",
       "      <td>0.956905</td>\n",
       "      <td>0.957414</td>\n",
       "      <td>0.957923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.820269</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.810994</td>\n",
       "      <td>0.817272</td>\n",
       "      <td>0.823549</td>\n",
       "      <td>0.824907</td>\n",
       "      <td>0.826264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.954530</td>\n",
       "      <td>0.960129</td>\n",
       "      <td>0.965728</td>\n",
       "      <td>0.967764</td>\n",
       "      <td>0.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.975908</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.974550</td>\n",
       "      <td>0.974890</td>\n",
       "      <td>0.975229</td>\n",
       "      <td>0.976586</td>\n",
       "      <td>0.977944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    accuracy  \\\n",
       "                                                                       count   \n",
       "models                                             lab  data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%              3.0   \n",
       "                                                        100%             3.0   \n",
       "                                                        30%              3.0   \n",
       "                                                        5%               3.0   \n",
       "                                                        50%              3.0   \n",
       "                                                        70%              3.0   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                         mean   \n",
       "models                                             lab  data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.902047   \n",
       "                                                        100%         0.976021   \n",
       "                                                        30%          0.957245   \n",
       "                                                        5%           0.820269   \n",
       "                                                        50%          0.963353   \n",
       "                                                        70%          0.975908   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                          std   \n",
       "models                                             lab  data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.000706   \n",
       "                                                        100%         0.007296   \n",
       "                                                        30%          0.000588   \n",
       "                                                        5%           0.008146   \n",
       "                                                        50%          0.007907   \n",
       "                                                        70%          0.001796   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                          min   \n",
       "models                                             lab  data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.901256   \n",
       "                                                        100%         0.968782   \n",
       "                                                        30%          0.956905   \n",
       "                                                        5%           0.810994   \n",
       "                                                        50%          0.954530   \n",
       "                                                        70%          0.974550   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                          25%   \n",
       "models                                             lab  data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.901765   \n",
       "                                                        100%         0.972345   \n",
       "                                                        30%          0.956905   \n",
       "                                                        5%           0.817272   \n",
       "                                                        50%          0.960129   \n",
       "                                                        70%          0.974890   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                          50%   \n",
       "models                                             lab  data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.902273   \n",
       "                                                        100%         0.975908   \n",
       "                                                        30%          0.956905   \n",
       "                                                        5%           0.823549   \n",
       "                                                        50%          0.965728   \n",
       "                                                        70%          0.975229   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                          75%   \n",
       "models                                             lab  data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.902443   \n",
       "                                                        100%         0.979640   \n",
       "                                                        30%          0.957414   \n",
       "                                                        5%           0.824907   \n",
       "                                                        50%          0.967764   \n",
       "                                                        70%          0.976586   \n",
       "\n",
       "                                                                               \n",
       "                                                                          max  \n",
       "models                                             lab  data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 100% 10%          0.902613  \n",
       "                                                        100%         0.983373  \n",
       "                                                        30%          0.957923  \n",
       "                                                        5%           0.826264  \n",
       "                                                        50%          0.969800  \n",
       "                                                        70%          0.977944  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "har5%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 5 val_loss: 0.6508865955121079 val_acc: 0.7553444180522565\n",
      "har10%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 11 val_loss: 0.37507563022431145 val_acc: 0.8961655921275874\n",
      "har30%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 10 val_loss: 0.23837404603831922 val_acc: 0.9491007804546997\n",
      "har50%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 1 val_loss: 0.1840641939482286 val_acc: 0.9474041398031897\n",
      "har70%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 10 val_loss: 0.0867358241843336 val_acc: 0.9752290464879538\n",
      "har100%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 32 val_loss: 0.09407840634266076 val_acc: 0.9799796403121819\n",
      "har5%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 4 val_loss: 0.67058725331976 val_acc: 0.7451645741431965\n",
      "har10%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 2 val_loss: 0.3828051966413714 val_acc: 0.8758059043094673\n",
      "har30%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 13 val_loss: 0.22198712692286637 val_acc: 0.9555480149304377\n",
      "har50%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 2 val_loss: 0.14022412403664591 val_acc: 0.9572446555819477\n",
      "har70%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 4 val_loss: 0.06980159107126703 val_acc: 0.9779436715303699\n",
      "har100%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 2 val_loss: 0.1130930731811886 val_acc: 0.9687818120122158\n",
      "har5%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 2 val_loss: 0.6709550162837349 val_acc: 0.7485578554462164\n",
      "har10%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 4 val_loss: 0.40490604442088257 val_acc: 0.8853070919579233\n",
      "har30%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 10 val_loss: 0.17537192939134383 val_acc: 0.9572446555819477\n",
      "har50%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 8 val_loss: 0.06910250322026726 val_acc: 0.9762470308788599\n",
      "har70%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 4 val_loss: 0.08426787693863769 val_acc: 0.9708177807940278\n",
      "har100%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 21 val_loss: 0.09288473132508548 val_acc: 0.9759077027485579\n"
     ]
    }
   ],
   "source": [
    "for k,t in data_trainers.items(): \n",
    "    for e, h in enumerate(t.history[::-1]):\n",
    "        if h[\"valid_acc_best\"]:\n",
    "            print(k, \"epoch:\", len(t.history)-e, \n",
    "                  \"val_loss:\", h[\"valid_loss\"], \n",
    "                  \"val_acc:\", h[\"valid_acc\"])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Label Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab600%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab600%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 1.7390090251802226\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab1200%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab1200%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 1.7610424022816948\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.7200405452871954\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab5%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab5%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.21118400482796504\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 0.18515581877546308\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab30%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab30%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 7 val_loss: 0.15340555996501667\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab50%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab50%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 3 val_loss: 0.13518715301205597\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.1724112945611007\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab600%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab600%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 1.7322869371227139\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab1200%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab1200%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 1.7546192825467537\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.7758566811402705\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab5%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab5%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.2090293009239899\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.17287611977545173\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab30%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab30%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 7 val_loss: 0.13708012452722607\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab50%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab50%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 8 val_loss: 0.1306835345425847\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.13504620766615438\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab600%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab600%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 8 val_loss: 1.7784707314045016\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab1200%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab1200%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 11 val_loss: 1.6985655392393404\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.7533347414111865\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab5%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab5%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.1785296278967468\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.20669979753031503\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab30%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab30%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.12918115916153466\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading har50%_lab50%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab50%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 3 val_loss: 0.1595142249297319\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading har50%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har50%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 2 val_loss: 0.10383275301932965\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [0.5]:\n",
    "        for label_perc in label_percentages:\n",
    "            is_retrain = IS_RETRAIN\n",
    "            if label_perc == 1: #already computed previous cell\n",
    "                is_retrain = False\n",
    "\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">ssl_classifier_gnp_large_shared_bottleneck_finetune</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.868793</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.867323</td>\n",
       "      <td>0.868001</td>\n",
       "      <td>0.868680</td>\n",
       "      <td>0.869528</td>\n",
       "      <td>0.870377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944237</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.942654</td>\n",
       "      <td>0.943502</td>\n",
       "      <td>0.944350</td>\n",
       "      <td>0.945029</td>\n",
       "      <td>0.945707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.954530</td>\n",
       "      <td>0.960129</td>\n",
       "      <td>0.965728</td>\n",
       "      <td>0.967764</td>\n",
       "      <td>0.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.337066</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.314218</td>\n",
       "      <td>0.329318</td>\n",
       "      <td>0.344418</td>\n",
       "      <td>0.348490</td>\n",
       "      <td>0.352562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.959394</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.958602</td>\n",
       "      <td>0.958602</td>\n",
       "      <td>0.958602</td>\n",
       "      <td>0.959790</td>\n",
       "      <td>0.960977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.937790</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.932474</td>\n",
       "      <td>0.933492</td>\n",
       "      <td>0.934510</td>\n",
       "      <td>0.940448</td>\n",
       "      <td>0.946386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.962787</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.959281</td>\n",
       "      <td>0.961147</td>\n",
       "      <td>0.963013</td>\n",
       "      <td>0.964540</td>\n",
       "      <td>0.966067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600%</th>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.016940</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.312182</td>\n",
       "      <td>0.316932</td>\n",
       "      <td>0.328639</td>\n",
       "      <td>0.340346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     accuracy  \\\n",
       "                                                                        count   \n",
       "models                                             lab   data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%              3.0   \n",
       "                                                   10%   50%              3.0   \n",
       "                                                   100%  50%              3.0   \n",
       "                                                   1200% 50%              3.0   \n",
       "                                                   30%   50%              3.0   \n",
       "                                                   5%    50%              3.0   \n",
       "                                                   50%   50%              3.0   \n",
       "                                                   600%  50%              3.0   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                          mean   \n",
       "models                                             lab   data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.868793   \n",
       "                                                   10%   50%          0.944237   \n",
       "                                                   100%  50%          0.963353   \n",
       "                                                   1200% 50%          0.337066   \n",
       "                                                   30%   50%          0.959394   \n",
       "                                                   5%    50%          0.937790   \n",
       "                                                   50%   50%          0.962787   \n",
       "                                                   600%  50%          0.321570   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           std   \n",
       "models                                             lab   data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.001530   \n",
       "                                                   10%   50%          0.001530   \n",
       "                                                   100%  50%          0.007907   \n",
       "                                                   1200% 50%          0.020202   \n",
       "                                                   30%   50%          0.001371   \n",
       "                                                   5%    50%          0.007514   \n",
       "                                                   50%   50%          0.003399   \n",
       "                                                   600%  50%          0.016940   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           min   \n",
       "models                                             lab   data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.867323   \n",
       "                                                   10%   50%          0.942654   \n",
       "                                                   100%  50%          0.954530   \n",
       "                                                   1200% 50%          0.314218   \n",
       "                                                   30%   50%          0.958602   \n",
       "                                                   5%    50%          0.932474   \n",
       "                                                   50%   50%          0.959281   \n",
       "                                                   600%  50%          0.307431   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           25%   \n",
       "models                                             lab   data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.868001   \n",
       "                                                   10%   50%          0.943502   \n",
       "                                                   100%  50%          0.960129   \n",
       "                                                   1200% 50%          0.329318   \n",
       "                                                   30%   50%          0.958602   \n",
       "                                                   5%    50%          0.933492   \n",
       "                                                   50%   50%          0.961147   \n",
       "                                                   600%  50%          0.312182   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           50%   \n",
       "models                                             lab   data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.868680   \n",
       "                                                   10%   50%          0.944350   \n",
       "                                                   100%  50%          0.965728   \n",
       "                                                   1200% 50%          0.344418   \n",
       "                                                   30%   50%          0.958602   \n",
       "                                                   5%    50%          0.934510   \n",
       "                                                   50%   50%          0.963013   \n",
       "                                                   600%  50%          0.316932   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           75%   \n",
       "models                                             lab   data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.869528   \n",
       "                                                   10%   50%          0.945029   \n",
       "                                                   100%  50%          0.967764   \n",
       "                                                   1200% 50%          0.348490   \n",
       "                                                   30%   50%          0.959790   \n",
       "                                                   5%    50%          0.940448   \n",
       "                                                   50%   50%          0.964540   \n",
       "                                                   600%  50%          0.328639   \n",
       "\n",
       "                                                                                \n",
       "                                                                           max  \n",
       "models                                             lab   data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%    50%          0.870377  \n",
       "                                                   10%   50%          0.945707  \n",
       "                                                   100%  50%          0.969800  \n",
       "                                                   1200% 50%          0.352562  \n",
       "                                                   30%   50%          0.960977  \n",
       "                                                   5%    50%          0.946386  \n",
       "                                                   50%   50%          0.966067  \n",
       "                                                   600%  50%          0.340346  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "har50%_lab600%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 3 val_loss: 1.783490130688564 val_acc: 0.3169324737020699\n",
      "har50%_lab1200%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 21 val_loss: 1.7878198685142845 val_acc: 0.3525619273837801\n",
      "har50%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 11 val_loss: 1.0262672793553742 val_acc: 0.8673227010519172\n",
      "har50%_lab5%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 9 val_loss: 0.25123960873940704 val_acc: 0.9324737020699015\n",
      "har50%_lab10%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 15 val_loss: 0.3563840006180122 val_acc: 0.9443501866304717\n",
      "har50%_lab30%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 32 val_loss: 0.2326741750093893 val_acc: 0.9586019681031558\n",
      "har50%_lab50%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 17 val_loss: 0.1826831086999811 val_acc: 0.9630132337970818\n",
      "har50%_lab100%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 2 val_loss: 0.1724112945611007 val_acc: 0.9545300305395318\n",
      "har50%_lab600%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 11 val_loss: 1.7820056427686062 val_acc: 0.30743128605361386\n",
      "har50%_lab1200%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 8 val_loss: 1.771115527340708 val_acc: 0.3142178486596539\n",
      "har50%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 3 val_loss: 0.8002413715554125 val_acc: 0.8686800135731252\n",
      "har50%_lab5%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 4 val_loss: 0.24721342679157393 val_acc: 0.9463861554122837\n",
      "har50%_lab10%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 27 val_loss: 0.31698649787967553 val_acc: 0.9457074991516796\n",
      "har50%_lab30%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 21 val_loss: 0.16805327808327056 val_acc: 0.9586019681031558\n",
      "har50%_lab50%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 21 val_loss: 0.18034507405527334 val_acc: 0.9660671869697998\n",
      "har50%_lab100%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 5 val_loss: 0.15754291822759023 val_acc: 0.9697997964031219\n",
      "har50%_lab600%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 8 val_loss: 1.7784707314045016 val_acc: 0.34034611469290804\n",
      "har50%_lab1200%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 11 val_loss: 1.6985655392393404 val_acc: 0.34441805225653205\n",
      "har50%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 2 val_loss: 0.7533347414111865 val_acc: 0.8703766542246352\n",
      "har50%_lab5%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 5 val_loss: 0.28156970418587923 val_acc: 0.9345096708517137\n",
      "har50%_lab10%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 21 val_loss: 0.32307475200539165 val_acc: 0.9426535459789617\n",
      "har50%_lab30%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 14 val_loss: 0.13346982402723848 val_acc: 0.9609772650152698\n",
      "har50%_lab50%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 11 val_loss: 0.2007955954687292 val_acc: 0.9592806243637597\n",
      "har50%_lab100%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune epoch: 8 val_loss: 0.16306857743989744 val_acc: 0.9657278588394977\n"
     ]
    }
   ],
   "source": [
    "# if bad has to try freezing again and smaller params\n",
    "for k,t in data_trainers.items(): \n",
    "    for e, h in enumerate(t.history[::-1]):\n",
    "        if h[\"valid_acc_best\"]:\n",
    "            print(k, \"epoch:\", len(t.history)-e, \n",
    "                  \"val_loss:\", h[\"valid_loss\"], \n",
    "                  \"val_acc:\", h[\"valid_acc\"])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.9304 best without n max elements\n",
    "* 0.9277: jsd | no 0.1 scale | n_max_elements | 100 sampels | 0.05 entropies\n",
    "* 0.9857 : jsd | 0.1 scale | n_max_elements | 100 sampels | 0.05 entropies | no freeze\n",
    "* 0.9623 : jsd | no scale | n_max_elements | 100 sampels | 0.01 entropies | no freeze | no pretrain | [0.01,0.5] | linear interpolator (1,5)\n",
    "\n",
    "\n",
    "* 0.9671 : jsd | no scale ? | n_max_elements | 100 sampels | 0.05 entropies | no freeze | no pretrain | [0.1,0.5]\n",
    "* 0.9365 : jsd | no scale | n_max_elements | 100 sampels | 0.05 entropies | no freeze | no pretrain | [0.01,0.5] | linear interpolator\n",
    "* 0.9824 : jsd | no scale | n_max_elements | 100 sampels | 0.01 entropies | no freeze | no pretrain | [0.01,0.5] | linear interpolator\n",
    "\n",
    "\n",
    "* 0.9844 : jsd | no 0.1 scale | n_max_elements | 100 sampels | 0.05 entropies | no freeze\n",
    "* 0.9817 : jsd | no 0.1 scale | n_max_elements | 100 sampels | 0.05 entropies | no freeze | cntxt [0.01,0.5]\n",
    "\n",
    "\n",
    "* 0.9627 : jsd | no scale | n_max_elements | 100 sampels | 0.01 entropies | no freeze | no pretrain | [0.01,0.5]\n",
    "* 0.9572 : jsd | no scale | n_max_elements | 100 sampels | 0.01 entropies | no freeze | no pretrain | [0.01,0.9] | linear interpolator\n",
    "\n",
    "\n",
    "* 0.9321: jsd | no 0.1 scale | n_max_elements | 100 sampels\n",
    "* 0.9365: jsd | no 0.1 scale | n_max_elements | 100 sampels | 0.1 entropies\n",
    "\n",
    "\n",
    "* 0.9450 : jsd | 0.2 scale | n_max_elements | 100 sampels | 0.05 entropies | no freeze | no pretrain | [0.01,0.5]\n",
    "* 0.9315 : jsd | no scale | n_max_elements | 100 sampels | 0.05 entropies | no freeze | no pretrain | [0.01,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 5%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "5%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -2.164531707763672\n",
      "\n",
      "--- Loading 10%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "10%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -2.98053588682008\n",
      "\n",
      "--- Loading 30%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "30%har/transformer_gnp_large_shared_bottleneck best epoch: 87 val_loss: -4.5797279249117215\n",
      "\n",
      "--- Loading 50%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "50%har/transformer_gnp_large_shared_bottleneck best epoch: 72 val_loss: -5.531349883959131\n",
      "\n",
      "--- Loading 70%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "70%har/transformer_gnp_large_shared_bottleneck best epoch: 98 val_loss: -7.103462460897501\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n"
     ]
    }
   ],
   "source": [
    "# load all transformers\n",
    "loaded_models = {}\n",
    "for sampling_perc in sampling_percentages:\n",
    "    for k, m in models.items():\n",
    "        if \"transformer\" not in k:\n",
    "            continue\n",
    "            \n",
    "        out = train_models_({\"{}%har\".format(int(sampling_perc*100)): \n",
    "                                            (None, None)}, \n",
    "                              {k :m },\n",
    "                               chckpnt_dirname=chckpnt_dirname,\n",
    "                               is_retrain=False)\n",
    "        \n",
    "        pretrained_model = out[list(out.keys())[0]].module_\n",
    "        model_dict = models[k.replace(\"transformer\", \"ssl_classifier\")].state_dict()\n",
    "        model_dict.update(pretrained_model.state_dict())\n",
    "        models[k.replace(\"transformer\", \"ssl_classifier\")].load_state_dict(model_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal, Categorical, kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([0.2, 0.8], requires_grad=True)\n",
    "t2 = torch.tensor([0.7, 0.3], requires_grad=True)\n",
    "#torch.softmax(t2, -1)\n",
    "#torch.softmax(t1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = (t1 + t2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon_div(p1, p2):\n",
    "    p_avg = (p1 + p2) / 2\n",
    "    mask = (p_avg != 0).float()\n",
    "    # set to 0 p when M is 0 (because mean can only be 0 is vectors weree, but\n",
    "    # this is not the case due to numerical issues)\n",
    "    M = Categorical(probs=p_avg)\n",
    "    return ((kl_divergence(Categorical(probs=p1 * mask), M) +\n",
    "             kl_divergence(Categorical(probs=p2 * mask), M)) / 2)\n",
    "\n",
    "def yann_div(t1, t2):\n",
    "    M = (t1 + t2) / 2\n",
    "    return torch.min(kl_divergence(Categorical(probs=t1), Categorical(M)) + \n",
    "               kl_divergence(Categorical(probs=t2), Categorical(M)))\n",
    "\n",
    "def csiszar_dist(t1, t2):\n",
    "    M = (t1 + t2) / 2\n",
    "    return ((kl_divergence(Categorical(M), Categorical(probs=t1)\n",
    "                ) + kl_divergence(Categorical(M), Categorical(probs=t2)))/2)#**0.5\n",
    "\n",
    "def total_var(t1, t2):\n",
    "    return (t1 - t2).abs().sum(-1) / 2\n",
    "\n",
    "def bhattacharyya_dist(t1, t2):\n",
    "    return -torch.log((t1 * t2).sqrt().sum(-1))\n",
    "\n",
    "def hellinger_dist(t1, t2):\n",
    "    return (t1.sqrt() - t2.sqrt()).pow(2).sum(-1).sqrt() / (2**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t1,t2 in [([0., 1], [1, 0.]), \n",
    "              ([0.5, 0.5], [0.4, 0.6]), \n",
    "              ([0.5, 0.5], [0.5, 0.5]), \n",
    "              ([0.4, 0.6], [0.3, 0.7]), \n",
    "              ([1-1e-50, 1e-50], [1e-50, 1-1e-50]), \n",
    "              ([0.1, 0.1, 0.8], [0.2, 0.2, 0.6]), \n",
    "              ([0.1, 0.1, 0.8], [0.6, 0.2, 0.2])]:\n",
    "    print()\n",
    "    print(t1, t2)\n",
    "    print(\"yd\", yann_div(torch.tensor(t1), torch.tensor(t2)).item())\n",
    "    print(\"cd\", csiszar_dist(torch.tensor(t1), torch.tensor(t2)).item())\n",
    "    print(\"tv\", total_var(torch.tensor(t1), torch.tensor(t2)).item())\n",
    "    print(\"jsd\", jensen_shannon_div(torch.tensor(t1), torch.tensor(t2)).item())\n",
    "    print(\"bd\", bhattacharyya_dist(torch.tensor(t1), torch.tensor(t2)).item())\n",
    "    print(\"hd\", hellinger_dist(torch.tensor(t1), torch.tensor(t2)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
