{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition - SSL JOINT Consistency\n",
    "\n",
    "Last Update : 31 July 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8\n",
    "# Nota Bene : notebooks don't deallocate GPU memory\n",
    "IS_FORCE_CPU = False # can also be set in the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/conv\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "import os\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skssl.transformers.neuralproc.datasplit import CntxtTrgtGetter, GetRandomIndcs, get_all_indcs\n",
    "from utils.data.tsdata import get_timeseries_dataset, SparseMultiTimeSeriesDataset\n",
    "\n",
    "get_cntxt_trgt_test = CntxtTrgtGetter(contexts_getter=GetRandomIndcs(min_n_indcs=0.1, max_n_indcs=0.5),\n",
    "                                     targets_getter=get_all_indcs,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt_feat = CntxtTrgtGetter(contexts_getter=get_all_indcs,\n",
    "                                     targets_getter=get_all_indcs,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt = CntxtTrgtGetter(contexts_getter=GetRandomIndcs(min_n_indcs=0.01, max_n_indcs=0.99),\n",
    "                                 targets_getter=GetRandomIndcs(min_n_indcs=0.5, max_n_indcs=0.99),\n",
    "                                 is_add_cntxts_to_trgts=False)  # don't context points to tagrtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_both = get_timeseries_dataset(\"har\")(split=\"both\")\n",
    "\n",
    "def cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=False):\n",
    "    def mycollate(batch):\n",
    "        min_length = min([v.size(0) for b in batch for k,v in b[0].items() if \"X\" in k])\n",
    "        # chose first min_legth of each (assumes that randomized)\n",
    "        \n",
    "        batch = [({k:v[:min_length, ...] for k,v in b[0].items()}, b[1]) for b in batch]        \n",
    "        collated = torch.utils.data.dataloader.default_collate(batch)\n",
    "        \n",
    "        X = collated[0][\"X\"]\n",
    "        y = collated[0][\"y\"]\n",
    "        \n",
    "        if is_repeat_batch:\n",
    "            \n",
    "            X = torch.cat([X,X], dim=0)\n",
    "            y = torch.cat([y,y], dim=0)\n",
    "            collated[1] = torch.cat([collated[1], collated[1]], dim=0) # targets\n",
    "        \n",
    "        collated[0][\"X\"], collated[0][\"y\"], collated[0][\"X_trgt\"], collated[0][\"y_trgt\"] = get_cntxt_trgt(X, y)\n",
    "        \n",
    "        return collated\n",
    "    return mycollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 1  # 1D spatial input (although actually 2 but the first is for sparse channels)\n",
    "Y_DIM = data_both.data.shape[-1] # multiple channels\n",
    "N_TARGETS = len(np.unique(data_both.targets))\n",
    "\n",
    "sampling_percentages = [0.05, 0.1, 0.3, 0.5, 0.7, 1]\n",
    "label_percentages = [N_TARGETS, N_TARGETS*2, 0.01, 0.05, 0.1, 0.3, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from skssl.transformers import GlobalNeuralProcess, NeuralProcessLoss, AttentiveNeuralProcess, NeuralProcessSSLLoss\n",
    "from skssl.utils.helpers import rescale_range\n",
    "from skssl.predefined import UnetCNN, CNN, MLP, SparseSetConv, SetConv, MlpRBF, GaussianRBF, BatchSparseSetConv\n",
    "from skssl.transformers.neuralproc.datasplit import precomputed_cntxt_trgt_split\n",
    "from utils.helpers import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "models = {}\n",
    "\n",
    "min_std=5e-3\n",
    "\n",
    "unet = partial(UnetCNN,\n",
    "               Conv=torch.nn.Conv1d,\n",
    "               Pool=torch.nn.MaxPool1d,\n",
    "               upsample_mode=\"linear\",\n",
    "               n_layers=18,\n",
    "               is_double_conv=True,\n",
    "               is_depth_separable=True,\n",
    "               Normalization=torch.nn.BatchNorm1d,\n",
    "               is_chan_last=True,\n",
    "               bottleneck=None,\n",
    "               kernel_size=7,\n",
    "               max_nchannels=256,\n",
    "              is_force_same_bottleneck=True,\n",
    "               _is_summary=True,\n",
    "              )\n",
    "\n",
    "kwargs = dict(x_dim=X_DIM, \n",
    "              y_dim=Y_DIM,\n",
    "              min_std=min_std,\n",
    "                n_tmp_queries=128,\n",
    "                r_dim=64,\n",
    "              keys_to_tmp_attn=partial(SetConv, RadialBasisFunc=GaussianRBF),\n",
    "              TmpSelfAttn=unet,\n",
    "              tmp_to_queries_attn=partial(SetConv, RadialBasisFunc=GaussianRBF),\n",
    "              is_skip_tmp=False,\n",
    "              is_use_x=False,\n",
    "              get_cntxt_trgt=precomputed_cntxt_trgt_split,\n",
    "              is_encode_xy=False,\n",
    "             Classifier=partial(MLP, input_size=256+Y_DIM*4, output_size=N_TARGETS, \n",
    "                                dropout=0., hidden_size=128, n_hidden_layers=3, is_res=True))\n",
    "\n",
    "models[\"ssl_classifier_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs)\n",
    "\n",
    "kwargs_bis = deepcopy(kwargs)\n",
    "kwargs_bis[\"Classifier\"] = None\n",
    "\n",
    "models[\"transformer_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_classifier_gnp_large_shared_bottleneck - N Param: 1078238\n",
      "transformer_gnp_large_shared_bottleneck - N Param: 1006936\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import count_parameters\n",
    "for k,v in models.items():\n",
    "    print(k, \"- N Param:\", count_parameters(v()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_(models, sampling_percentages):\n",
    "    # ALREADY INITALIZE TO BE ABLE TO LOAD\n",
    "    models[\"ssl_classifier_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs)()\n",
    "\n",
    "    kwargs_bis = deepcopy(kwargs)\n",
    "    kwargs_bis[\"Classifier\"] = None\n",
    "\n",
    "    models[\"transformer_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs_bis)()\n",
    "\n",
    "    # load all transformers\n",
    "    loaded_models = {}\n",
    "    for sampling_perc in sampling_percentages:\n",
    "        for k, m in models.items():\n",
    "            if \"transformer\" not in k:\n",
    "                continue\n",
    "\n",
    "            out = train_models_({\"{}%har\".format(int(sampling_perc*100)): \n",
    "                                                (None, None)}, \n",
    "                                  {k :m },\n",
    "                                   chckpnt_dirname=chckpnt_dirname_old,\n",
    "                                seed=None,\n",
    "                                   is_retrain=False)\n",
    "\n",
    "            pretrained_model = out[list(out.keys())[0]].module_\n",
    "            model_dict = models[k.replace(\"transformer\", \"ssl_classifier\")].state_dict()\n",
    "            model_dict.update(pretrained_model.state_dict())\n",
    "            models[k.replace(\"transformer\", \"ssl_classifier\")].load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntbks_helpers import train_models_\n",
    "from skorch.dataset import CVSplit\n",
    "from utils.data.ssldata import get_train_dev_test_ssl\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 100 \n",
    "BATCH_SIZE = 32\n",
    "IS_RETRAIN = False # if false load precomputed\n",
    "chckpnt_dirname_old=\"results/challenge/har/\"\n",
    "chckpnt_dirname=\"results/challenge/har_new/\"\n",
    "\n",
    "from skssl.utils.helpers import HyperparameterInterpolator\n",
    "\n",
    "n_steps_per_epoch = len(data_both)//BATCH_SIZE\n",
    "get_lambda_clf=HyperparameterInterpolator(1, 10, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "7352\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug best epoch: 1 val_loss: 0.5792485174988745\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "7352\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug best epoch: 4 val_loss: 0.534082076773629\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "7352\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug best epoch: 7 val_loss: 0.5398399174557243\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=False)\n",
    "            print(len(data_train))\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_noaug\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_noaug</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.870264</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.866644</td>\n",
       "      <td>0.869359</td>\n",
       "      <td>0.872073</td>\n",
       "      <td>0.872073</td>\n",
       "      <td>0.872073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.870264   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.003135   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.866644   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.869359   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.872073   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.872073   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.872073  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "14530\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 4 val_loss: 0.7066817718074813\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "14530\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 1 val_loss: 0.7923410251903502\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "14530\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune best epoch: 3 val_loss: 0.7332448063763999\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "            print(len(data_train))\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.883497</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.876824</td>\n",
       "      <td>0.87886</td>\n",
       "      <td>0.880896</td>\n",
       "      <td>0.886834</td>\n",
       "      <td>0.892772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.883497   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.008286   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.876824   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        25%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.87886   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.880896   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.886834   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.892772  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Neg Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons best epoch: 1 val_loss: 0.5842806758175149\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons best epoch: 1 val_loss: 0.6183924950055038\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons best epoch: 1 val_loss: 0.6301195088345438\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):  \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nonegcons\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 1,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nonegcons</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.884968</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.880896</td>\n",
       "      <td>0.882592</td>\n",
       "      <td>0.884289</td>\n",
       "      <td>0.887004</td>\n",
       "      <td>0.889718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.884968   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        std   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.00445   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.880896   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.882592   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.884289   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.887004   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.889718  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show number of steps for convergence becauseprobably no unsup is fine but not improving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent best epoch: 1 val_loss: 0.6706024456477223\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent best epoch: 1 val_loss: 0.6930868627258914\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noent best epoch: 1 val_loss: 0.667854422668623\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_noent\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 1.,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_noent</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.881235</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.878521</td>\n",
       "      <td>0.880048</td>\n",
       "      <td>0.881574</td>\n",
       "      <td>0.882592</td>\n",
       "      <td>0.88361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.881235   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.002562   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.878521   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.880048   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.881574   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.882592   \n",
       "\n",
       "                                                                             \n",
       "                                                                        max  \n",
       "models                                             lab data sample           \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.88361  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup best epoch: 1 val_loss: 0.6362027577476903\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup best epoch: 1 val_loss: 0.6330289104488853\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup best epoch: 1 val_loss: 0.7715492812423007\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nounsup\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 0,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nounsup</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.871621</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.866305</td>\n",
       "      <td>0.870037</td>\n",
       "      <td>0.87377</td>\n",
       "      <td>0.874279</td>\n",
       "      <td>0.874788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.871621   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.004632   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.866305   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.870037   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                        50%   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.87377   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.874279   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.874788  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SSL Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly best epoch: 1 val_loss: 0.6721114105882182\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly best epoch: 1 val_loss: 0.6721089704181528\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly best epoch: 1 val_loss: 0.6721099129279752\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_sslonly\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=True,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_sslonly</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.876598</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.871395</td>\n",
       "      <td>0.874618</td>\n",
       "      <td>0.877842</td>\n",
       "      <td>0.879199</td>\n",
       "      <td>0.880556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.876598   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.004706   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.871395   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.874618   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.877842   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.879199   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.880556  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sup Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly best epoch: 2 val_loss: 0.37116682323149275\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly best epoch: 2 val_loss: 0.6973583848750674\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly best epoch: 3 val_loss: 0.5974679222178128\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = data_train.data[(data_train.targets!=-1).squeeze()]\n",
    "            data_train.targets = data_train.targets[(data_train.targets!=-1).squeeze()]\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_suponly\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=True,\n",
    "                                                    get_lambda_unsup=lambda: 0,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                               seed=None,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_suponly</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904083</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.892433</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.900916</td>\n",
       "      <td>0.909908</td>\n",
       "      <td>0.918901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.904083   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.013515   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.892433   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.896675   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.900916   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.909908   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.918901  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sup Only No Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.1423\u001b[0m       \u001b[32m0.9019\u001b[0m        \u001b[35m0.4632\u001b[0m     +  27.0568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.0234\u001b[0m       0.8789        0.6497        25.7552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.0150\u001b[0m       \u001b[32m0.9050\u001b[0m        0.5428     +  26.0485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        0.0204       0.8918        0.5845        26.6478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        \u001b[36m0.0135\u001b[0m       0.8873        0.7393        25.8290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        0.0190       0.9019        0.7017        26.0549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.0134\u001b[0m       0.8999        0.5504        26.9620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        \u001b[36m0.0126\u001b[0m       0.8789        0.8902        25.2579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        \u001b[36m0.0086\u001b[0m       0.8731        0.7300        25.8022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.0153       0.8775        0.6866        27.1475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.0087       0.8656        0.9808        26.2136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.0223       0.8534        0.7029        26.2065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.0141       0.8629        0.7914        26.4802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        \u001b[36m0.0085\u001b[0m       0.8799        0.7899        26.3274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.0179       0.8897        0.7920        25.8998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        \u001b[36m0.0041\u001b[0m       0.8887        0.7500        26.9822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.0186       0.8802        0.6499        26.4571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla best epoch: 1 val_loss: 0.46322141261598004\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.1631\u001b[0m       \u001b[32m0.9203\u001b[0m        \u001b[35m0.2856\u001b[0m     +  27.3947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.0199\u001b[0m       0.8941        0.5483        26.1763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        0.0238       \u001b[32m0.9253\u001b[0m        0.4433     +  26.1705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        0.0212       0.9104        0.5256        26.8947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        0.0202       0.9138        0.5036        26.1654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        0.0205       0.9030        0.5572        26.1184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        \u001b[36m0.0094\u001b[0m       0.9077        0.4847        26.9226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        0.0145       0.8880        0.7473        26.1455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        0.0171       0.9026        0.6188        25.7778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.0109       0.9050        0.5586        27.0420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.0110       0.8999        0.6263        25.9539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        \u001b[36m0.0043\u001b[0m       0.9050        0.8275        26.1571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.0076       0.8836        0.8493        26.7187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        0.0173       0.8890        0.6464        25.9694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.0217       0.8941        0.7561        26.5339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     16        0.0167       0.9026        0.7461        26.4009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     17        0.0144       0.8846        0.7837        25.7361\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla best epoch: 1 val_loss: 0.28563037815035747\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Training har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  ------------  -----------  ------------  ----  -------\n",
      "      1        \u001b[36m0.1328\u001b[0m       \u001b[32m0.8965\u001b[0m        \u001b[35m0.4885\u001b[0m     +  27.1879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      2        \u001b[36m0.0368\u001b[0m       0.8877        0.5944        25.6638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      3        \u001b[36m0.0232\u001b[0m       0.8911        0.5975        26.4048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      4        \u001b[36m0.0184\u001b[0m       0.8616        1.0288        27.0574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      5        0.0228       0.8775        0.6836        26.3406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      6        \u001b[36m0.0159\u001b[0m       0.8734        0.7550        26.1929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      7        0.0178       0.8694        0.6896        27.2681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      8        \u001b[36m0.0158\u001b[0m       0.8853        0.5319        26.1816\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      9        \u001b[36m0.0084\u001b[0m       0.8907        0.6725        26.1332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     10        0.0169       0.8765        0.6900        25.6314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     11        0.0109       0.8941        0.4913        25.9695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     12        0.0151       0.8758        0.6700        26.0417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     13        0.0265       0.8639        0.8402        26.9045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     14        \u001b[36m0.0056\u001b[0m       0.8717        0.8625        26.2144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "     15        0.0204       0.8775        0.5983        25.7190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_acc has not improved in the last 15 epochs.\n",
      "Re-initializing optimizer.\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla best epoch: 1 val_loss: 0.4885016896986027\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              dev_size=0,\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = data_train.data[(data_train.targets!=-1).squeeze()]\n",
    "            data_train.targets = data_train.targets[(data_train.targets!=-1).squeeze()]\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run):\n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_sup_vanilla\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda : 1,\n",
    "                                                    n_max_elements=None,\n",
    "                                                    label_perc=None, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=True,\n",
    "                                                    get_lambda_unsup=lambda: 0,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=True,\n",
    "                                               seed=None,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_sup_vanilla</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.896505</td>\n",
       "      <td>0.900747</td>\n",
       "      <td>0.904988</td>\n",
       "      <td>0.915168</td>\n",
       "      <td>0.925348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.908947   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.014823   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.896505   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.900747   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.904988   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.915168   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.925348  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Lambda CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda best epoch: 4 val_loss: 0.7258332047496442\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda best epoch: 2 val_loss: 0.8610166228339354\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda best epoch: 4 val_loss: 0.6764867800876655\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nolambda\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: 1,\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: .5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nolambda</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.88542</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.872073</td>\n",
       "      <td>0.880896</td>\n",
       "      <td>0.889718</td>\n",
       "      <td>0.892094</td>\n",
       "      <td>0.894469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                       mean   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.88542   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                       std   \n",
       "models                                             lab data sample           \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.0118   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.872073   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.880896   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.889718   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.892094   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.894469  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Label Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale best epoch: 1 val_loss: 1.3277767340450073\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale best epoch: 2 val_loss: 1.1983000453059698\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale best epoch: 3 val_loss: 1.0681789091250675\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_nolabscale\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=None, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_nolabscale</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.893677</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>0.881574</td>\n",
       "      <td>0.886834</td>\n",
       "      <td>0.892094</td>\n",
       "      <td>0.899729</td>\n",
       "      <td>0.907363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.893677   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.012967   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.881574   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.886834   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.892094   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.899729   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.907363  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Element Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale best epoch: 1 val_loss: 0.5697207075480812\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale best epoch: 2 val_loss: 0.7624972491981142\n",
      "\n",
      "--- Loading 100%har/transformer_gnp_large_shared_bottleneck ---\n",
      "\n",
      "100%har/transformer_gnp_large_shared_bottleneck best epoch: 86 val_loss: -8.16725208180622\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale best epoch: 1 val_loss: 0.649505396394114\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "\n",
    "            load_pretrained_(models, [sampling_perc])\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"_finetune_noelemscale\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=None,\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck_finetune_noelemscale</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.882366</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.878181</td>\n",
       "      <td>0.881235</td>\n",
       "      <td>0.884289</td>\n",
       "      <td>0.884459</td>\n",
       "      <td>0.884628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   accuracy  \\\n",
       "                                                                      count   \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%             3.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                        mean   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.882366   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         std   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.003628   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         min   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.878181   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         25%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.881235   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.884289   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         75%   \n",
       "models                                             lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.884459   \n",
       "\n",
       "                                                                              \n",
       "                                                                         max  \n",
       "models                                             lab data sample            \n",
       "ssl_classifier_gnp_large_shared_bottleneck_fine... 1%  100%         0.884628  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck ---\n",
      "\n",
      "har100%_lab1%_run0/ssl_classifier_gnp_large_shared_bottleneck best epoch: 1 val_loss: 0.8911615639651959\n",
      "\n",
      "--- Loading har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck ---\n",
      "\n",
      "har100%_lab1%_run1/ssl_classifier_gnp_large_shared_bottleneck best epoch: 2 val_loss: 0.5388232102667948\n",
      "\n",
      "--- Loading har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck ---\n",
      "\n",
      "har100%_lab1%_run2/ssl_classifier_gnp_large_shared_bottleneck best epoch: 1 val_loss: 0.8988694104252315\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import Freezer, LRScheduler\n",
    "\n",
    "data_trainers = {}\n",
    "models[\"ssl_classifier_gnp_large_shared_bottleneck\"] = partial(GlobalNeuralProcess, **kwargs)\n",
    "\n",
    "for run in range(3):\n",
    "    for sampling_perc in [1]:\n",
    "        for label_perc in [0.01]:\n",
    "\n",
    "            get_lambda_clf=HyperparameterInterpolator(1, 50, N_EPOCHS*n_steps_per_epoch, mode=\"linear\")\n",
    "\n",
    "            data_train, _, data_test = get_train_dev_test_ssl(\"har\", \n",
    "                                                              n_labels=label_perc, \n",
    "                                                              data_perc=sampling_perc, \n",
    "                                                              dev_size=0,\n",
    "                                                              seed=random.randint(0,10000),\n",
    "                                                              is_augment=True)\n",
    "\n",
    "            # add test as unlabeled data\n",
    "            data_train.data = np.concatenate([data_train.data, data_test.data], axis=0)\n",
    "            data_train.targets = np.concatenate([data_train.targets, -1*np.ones_like(data_test.targets)], axis=0)\n",
    "            data_train.indcs = np.concatenate([data_train.indcs, data_test.indcs], axis=0)\n",
    "\n",
    "            data_trainers.update(train_models_({\"har{}%_lab{}%_run{}\".format(int(sampling_perc*100), int(label_perc*100), run): \n",
    "                                                (data_train, data_test)}, \n",
    "                                  {k + \"\" :m for k,m in models.items() if \"ssl_classifier\" in k}, \n",
    "                                  criterion=partial(NeuralProcessSSLLoss, \n",
    "                                                    get_lambda_sup=lambda: get_lambda_clf(True),\n",
    "                                                    n_max_elements=int(128*sampling_perc),\n",
    "                                                    label_perc=(label_perc * data_train.n_train)/data_train.n_total, # label perc is lower ebcause cocnat to test\n",
    "                                                    min_sigma=min_std,\n",
    "                                                    is_unsup_forall=False,\n",
    "                                                    is_ssl_only=False,\n",
    "                                                    get_lambda_unsup=lambda: 1,\n",
    "                                                     get_lambda_ent=lambda: 0.5,  # both do something similar\n",
    "                                                     get_lambda_neg_cons=lambda: 0.5,\n",
    "                                                    ),\n",
    "                                    patience=15,\n",
    "                                  chckpnt_dirname=chckpnt_dirname,\n",
    "                                  max_epochs=N_EPOCHS,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  is_retrain=IS_RETRAIN,\n",
    "                                    is_monitor_acc=True,\n",
    "                                  callbacks=[],\n",
    "                                  iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=True),  \n",
    "                                  iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_feat),\n",
    "                                              ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th>lab</th>\n",
       "      <th>data sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ssl_classifier_gnp_large_shared_bottleneck</th>\n",
       "      <th>1%</th>\n",
       "      <th>100%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.862007</td>\n",
       "      <td>0.017089</td>\n",
       "      <td>0.850017</td>\n",
       "      <td>0.852223</td>\n",
       "      <td>0.854428</td>\n",
       "      <td>0.868001</td>\n",
       "      <td>0.881574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy            \\\n",
       "                                                              count      mean   \n",
       "models                                     lab data sample                      \n",
       "ssl_classifier_gnp_large_shared_bottleneck 1%  100%             3.0  0.862007   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 std   \n",
       "models                                     lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck 1%  100%         0.017089   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 min   \n",
       "models                                     lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck 1%  100%         0.850017   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 25%   \n",
       "models                                     lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck 1%  100%         0.852223   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 50%   \n",
       "models                                     lab data sample             \n",
       "ssl_classifier_gnp_large_shared_bottleneck 1%  100%         0.854428   \n",
       "\n",
       "                                                                                \n",
       "                                                                 75%       max  \n",
       "models                                     lab data sample                      \n",
       "ssl_classifier_gnp_large_shared_bottleneck 1%  100%         0.868001  0.881574  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = pd.Series({k:v.history[-1][\"valid_acc\"] for k,v in data_trainers.items()}).reset_index(name=\"accuracy\")\n",
    "splitted = out[\"index\"].str.split(\"/\", expand = True)\n",
    "out[\"meta\"] = splitted[0]\n",
    "out[\"models\"] = splitted[1]\n",
    "\n",
    "splitted2 = out[\"meta\"].str.split(\"_run\", expand = True)\n",
    "out[\"meta\"] = splitted2[0]\n",
    "out[\"run\"] = splitted2[1]\n",
    "\n",
    "splitted3 = out[\"meta\"].str.split(\"_lab\", expand = True)\n",
    "out[\"data sample\"] = splitted3[0].str.split(\"har\", expand = True)[1]\n",
    "out[\"lab\"] = splitted3[1]\n",
    "\n",
    "\n",
    "out.drop(columns =[\"index\"], inplace = True) \n",
    "\n",
    "out.groupby([\"models\", \"lab\", \"data sample\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
