{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/conv\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%pdb\n",
    "\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from utils.data import get_train_dev_test_ssl\n",
    "from pretrained import load_pretrained\n",
    "from skssl.classifiers import LabelSpreading\n",
    "from skssl.meta import SelfTrainingMeta\n",
    "from skssl.classifiers.sslvae import SSLVAE, SSLVAELoss\n",
    "from skssl.training import NeuralNetClassifier, NeuralNetEstimator\n",
    "from skssl.predefined import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist 0.9933\n",
      "svhn 0.9596266133988937\n",
      "cifar10 0.8974\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\n",
    "    print(dataset)\n",
    "    train, dev, test = get_train_dev_test_ssl(dataset)\n",
    "    \n",
    "    classifier = load_pretrained(\"supervised\", dataset, is_all_labels=True, is_retrain=False)\n",
    "    \n",
    "    print(dataset, classifier.score(test, test.targets))\n",
    "\"\"\"\n",
    "    \n",
    "print(\"mnist 0.9933\")\n",
    "print(\"svhn 0.9596266133988937\")\n",
    "print(\"cifar10 0.8974\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNP ALL Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist 0.9953\n",
      "svhn 0.958090\n",
      "cifar10 0.8421\n"
     ]
    }
   ],
   "source": [
    "print(\"mnist 0.9953\")\n",
    "print(\"svhn 0.958090\")\n",
    "print(\"cifar10 0.8421\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport random\\nfor run in range(2):\\n    for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\\n        train, dev, test = get_train_dev_test_ssl(dataset)\\n\\n        classifier = load_pretrained(\"supervised\", dataset, is_retrain=True, suffix=\"_run{}\".format(run), \\n                                     seed=random.randint(1000))\\n\\n        print(dataset, classifier.score(test, test.targets))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import random\n",
    "for run in range(2):\n",
    "    for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\n",
    "        train, dev, test = get_train_dev_test_ssl(dataset)\n",
    "\n",
    "        classifier = load_pretrained(\"supervised\", dataset, is_retrain=True, suffix=\"_run{}\".format(run), \n",
    "                                     seed=random.randint(1000))\n",
    "\n",
    "        print(dataset, classifier.score(test, test.targets))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor run in range(3):\\n    for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\\n        train, dev, test = get_train_dev_test_ssl(dataset)\\n\\n        classifier = load_pretrained(\"supervised\", dataset, is_retrain=False ,\\n                                     suffix=\"_run{}\".format(run) if run != 2 else \"\")\\n\\n        print(dataset, classifier.score(test, test.targets))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for run in range(3):\n",
    "    for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\n",
    "        train, dev, test = get_train_dev_test_ssl(dataset)\n",
    "\n",
    "        classifier = load_pretrained(\"supervised\", dataset, is_retrain=False ,\n",
    "                                     suffix=\"_run{}\".format(run) if run != 2 else \"\")\n",
    "\n",
    "        print(dataset, classifier.score(test, test.targets))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist 0.6652 0.035990832165983595\n",
      "cifar10 0.7004 0.02696825294057193\n",
      "svhn 0.8380967014955951 0.007368153585755297\n"
     ]
    }
   ],
   "source": [
    "print(\"mnist\", np.array([0.6613, 0.6232, 0.7111]).mean(), np.array([0.6613, 0.6232, 0.7111]).std())\n",
    "print(\"cifar10\", np.array([0.7105, 0.6635, 0.7272]).mean(), np.array([0.7105, 0.6635, 0.7272]).std())\n",
    "print(\"svhn\", np.array([0.8305931161647203, 0.8355869698832207, 0.8481100184388445]).mean(), \n",
    "      np.array([0.8305931161647203, 0.8355869698832207, 0.8481100184388445]).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Labes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('mnist', 'resnet', 'LabelSpreading') 0.9281\n",
      "Using downloaded and verified file: /conv/utils/data/../../data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /conv/utils/data/../../data/SVHN/test_32x32.mat\n",
      "\n",
      "('svhn', 'resnet', 'LabelSpreading') 0.5156730178242164\n"
     ]
    }
   ],
   "source": [
    "# could use pipleine but want only to transform once\n",
    "transformed = dict() # store all\n",
    "scores = dict()\n",
    "is_all_labels = True\n",
    "\n",
    "for dataset in [\"mnist\",\"svhn\"]: #\"cifar10\"\n",
    "    transformed[dataset] = dict()\n",
    "    train, dev, test = get_train_dev_test_ssl(dataset, is_all_labels=is_all_labels)\n",
    "    \n",
    "    for enc_dec in [\"resnet\"]: # \"cnn\" , \"resnetEnc_cnnDec\"  much worst\n",
    "        vae = load_pretrained(\"vae\", dataset, enc_dec=enc_dec).freeze()\n",
    "        transformed[dataset][(enc_dec,\"train\")] = vae.transform(train)\n",
    "        transformed[dataset][(enc_dec,\"test\")] = vae.transform(test)\n",
    "        \n",
    "        print()\n",
    "        for name, classifier in [(\"LabelSpreading\",LabelSpreading()),\n",
    "                                 #(\"SelfTraining MLP\", SelfTrainingMeta(MLPClassifier(solver=\"lbfgs\"), max_iter=50)), # much worst\n",
    "                                 #(\"Supervised MLP\", MLPClassifier(solver=\"lbfgs\"))\n",
    "                                ]:\n",
    "            \n",
    "            _ = classifier.fit(transformed[dataset][(enc_dec,\"train\")], train.targets)\n",
    "            y_hat = classifier.predict(transformed[dataset][(enc_dec,\"test\")])\n",
    "            scores[(dataset, enc_dec, name)] = accuracy_score(test.targets, y_hat)\n",
    "            print((dataset, enc_dec, name), scores[(dataset, enc_dec, name)])\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# could use pipleine but want only to transform once\n",
    "transformed = dict() # store all\n",
    "scores = dict()\n",
    "is_all_labels = False\n",
    "\n",
    "for dataset in [\"mnist\",\"svhn\"]: #\"cifar10\"\n",
    "    transformed[dataset] = dict()\n",
    "    train, dev, test = get_train_dev_test_ssl(dataset, is_all_labels=is_all_labels)\n",
    "    \n",
    "    for enc_dec in [\"resnet\"]: # \"cnn\" , \"resnetEnc_cnnDec\"  much worst\n",
    "        vae = load_pretrained(\"vae\", dataset, enc_dec=enc_dec).freeze()\n",
    "        transformed[dataset][(enc_dec,\"train\")] = vae.transform(train)\n",
    "        transformed[dataset][(enc_dec,\"test\")] = vae.transform(test)\n",
    "        \n",
    "        print()\n",
    "        for name, classifier in [(\"LabelSpreading\",LabelSpreading()),\n",
    "                                 #(\"SelfTraining MLP\", SelfTrainingMeta(MLPClassifier(solver=\"lbfgs\"), max_iter=50)), # much worst\n",
    "                                 #(\"Supervised MLP\", MLPClassifier(solver=\"lbfgs\"))\n",
    "                                ]:\n",
    "            \n",
    "            _ = classifier.fit(transformed[dataset][(enc_dec,\"train\")], train.targets)\n",
    "            y_hat = classifier.predict(transformed[dataset][(enc_dec,\"test\")])\n",
    "            scores[(dataset, enc_dec, name)] = accuracy_score(test.targets, y_hat)\n",
    "            print((dataset, enc_dec, name), scores[(dataset, enc_dec, name)])\n",
    "            \n",
    "# ('mnist', 'resnetEnc_cnnDec', 'LabelSpreading') 0.2797\n",
    "# ('mnist', 'resnetEnc_cnnDec', 'SelfTraining MLP') 0.1135\n",
    "# ('mnist', 'resnet', 'LabelSpreading') 0.8554\n",
    "# ('mnist', 'resnet', 'SelfTraining MLP') 0.8045\n",
    "# ('mnist', 'cnn', 'LabelSpreading') 0.1032\n",
    "# ('mnist', 'cnn', 'SelfTraining MLP') 0.1135\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSLVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=74. Setting it to 74.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist 0.9654\n",
      "Using downloaded and verified file: /master/utils/data/../../data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /master/utils/data/../../data/SVHN/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=74. Setting it to 74.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svhn 0.15964966195451752\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=74. Setting it to 74.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10 0.4695\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\n",
    "    train, dev, test = get_train_dev_test_ssl(dataset)\n",
    "    \n",
    "    classifier = load_pretrained(\"sslvae\", dataset, mode=\"m2\", z_dim=64)\n",
    "    \n",
    "    print(dataset, classifier.score(test, test.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1 + M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=64 and input=64. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=74. Setting it to 74.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=64 and input=74. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist 0.4478\n",
      "Using downloaded and verified file: /master/utils/data/../../data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /master/utils/data/../../data/SVHN/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=64 and input=64. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=74. Setting it to 74.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=64 and input=74. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svhn 0.301359864781807\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=64 and input=64. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=74. Setting it to 74.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=64 and input=74. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10 0.2093\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\n",
    "    train, dev, test = get_train_dev_test_ssl(dataset)\n",
    "    \n",
    "    classifier = load_pretrained(\"sslvae\", dataset, mode=\"m1+m2\", z_dim=64)\n",
    "    \n",
    "    print(dataset, classifier.score(test, test.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=64. Setting it to 64.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n",
      "/master/skssl/predefined/mlp.py:52: UserWarning: hidden_size=32 smaller than output=128 and input=138. Setting it to 128.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/pretrained/sslvae/auxiliary_z64_mnist/history.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ac03c54ba480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_dev_test_ssl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sslvae\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auxiliary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/master/pretrained.py\u001b[0m in \u001b[0;36mload_pretrained\u001b[0;34m(model, dataset, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pretrained_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sslvae\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pretrained_sslvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unkown model={}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/master/pretrained.py\u001b[0m in \u001b[0;36m_pretrained_sslvae\u001b[0;34m(dataset, z_dim, mode, transf_dec, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                              \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                              \u001b[0mTrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNeuralNetClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/master/pretrained.py\u001b[0m in \u001b[0;36m_pretrained_base\u001b[0;34m(model, criterion, dataset, chckpt_name, is_retrain, transformer, Trainer, basedir, seed, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36mload_params\u001b[0;34m(self, f, f_params, f_optimizer, f_history, checkpoint)\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf_history\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_history\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_history_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m             \u001b[0mformatted_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_formatted_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m             \u001b[0mf_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_params\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mformatted_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/history.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, f)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \"\"\"\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/utils.py\u001b[0m in \u001b[0;36mopen_file_like\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/pretrained/sslvae/auxiliary_z64_mnist/history.json'"
     ]
    }
   ],
   "source": [
    "for dataset in [\"mnist\",\"svhn\",\"cifar10\"]:\n",
    "    train, dev, test = get_train_dev_test_ssl(dataset)\n",
    "    \n",
    "    classifier = load_pretrained(\"sslvae\", dataset, mode=\"auxiliary\", z_dim=64)\n",
    "    \n",
    "    print(dataset, classifier.score(test, test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
