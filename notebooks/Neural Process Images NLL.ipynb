{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6 : Neural Process Images\n",
    "\n",
    "Last Update : 25 July 2019\n",
    "\n",
    "**Aim**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8\n",
    "# Nota Bene : notebooks don't deallocate GPU memory\n",
    "IS_FORCE_CPU = True # can also be set in the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/conv\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "import os\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "\n",
    "SVHN \n",
    "MNIST\n",
    "CELEBA\n",
    "CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntbks_add_data as adddata \n",
    "from functools import partial\n",
    "from utils.data.ssldata import get_dataset, get_train_dev_test_ssl\n",
    "from utils.data.helpers import train_dev_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /conv/utils/data/../../data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /conv/utils/data/../../data/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "celeba_train, celeba_test = train_dev_split(adddata.get_dataset(\"celeba\")(), dev_size=0.1, is_stratify=False)\n",
    "svhn_train, _, svhn_test = get_train_dev_test_ssl(\"svhn\", dev_size=0)\n",
    "#cifar10_train, _, cifar10_test = get_train_dev_test_ssl(\"cifar10\", dev_size=0)\n",
    "mnist_train, _, mnist_test = get_train_dev_test_ssl(\"mnist\", dev_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skssl.transformers.neuralproc.datasplit import GridCntxtTrgtGetter, RandomMasker, no_masker, half_masker\n",
    "from utils.data.tsdata import get_timeseries_dataset, SparseMultiTimeSeriesDataset\n",
    "\n",
    "get_cntxt_trgt_test = GridCntxtTrgtGetter(context_masker=RandomMasker(min_nnz=0.01, max_nnz=0.50),\n",
    "                                     target_masker=no_masker,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt_feat = GridCntxtTrgtGetter(context_masker=no_masker,\n",
    "                                     target_masker=no_masker,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt = GridCntxtTrgtGetter(context_masker=RandomMasker(min_nnz=0.01, max_nnz=0.50),\n",
    "                                 target_masker=RandomMasker(min_nnz=0.50, max_nnz=0.99),\n",
    "                                 is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "def cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=False, is_grided=False):\n",
    "    def mycollate(batch):\n",
    "        \n",
    "        if isinstance(batch[0][0], dict):\n",
    "            min_length = min([v.size(0) for b in batch for k,v in b[0].items() if \"X\" in k])\n",
    "            # chose first min_legth of each (assumes that randomized)\n",
    "\n",
    "            batch = [({k:v[:min_length, ...] for k,v in b[0].items()}, b[1]) for b in batch]        \n",
    "            collated = torch.utils.data.dataloader.default_collate(batch)\n",
    "        \n",
    "            X = collated[0][\"X\"]\n",
    "            y = collated[0][\"y\"]\n",
    "        else:       \n",
    "            collated = torch.utils.data.dataloader.default_collate(batch)\n",
    "            \n",
    "            X = collated[0]\n",
    "            y = None\n",
    "            collated[0] = dict()\n",
    "        \n",
    "        if is_repeat_batch:\n",
    "            X = torch.cat([X,X], dim=0)\n",
    "            if y is not None:\n",
    "                y = torch.cat([y,y], dim=0)\n",
    "            collated[1] = torch.cat([collated[1], collated[1]], dim=0) # targets\n",
    "        \n",
    "        if is_grided:\n",
    "            collated = (dict(), collated[1])\n",
    "            collated[0][\"X\"], collated[0][\"mask_context\"], collated[0][\"mask_target\"] = get_cntxt_trgt(X, y, \n",
    "                                                                                                       is_grided=True)\n",
    "            \n",
    "        else:\n",
    "            collated[0][\"X\"], collated[0][\"y\"], collated[0][\"X_trgt\"], collated[0][\"y_trgt\"] = get_cntxt_trgt(X, y)\n",
    "            \n",
    "        \n",
    "        return collated\n",
    "    return mycollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict(svhn=(svhn_train, svhn_test), \n",
    "                #cifar10=(cifar10_train, cifar10_test), \n",
    "                celeba=(celeba_train, celeba_test),\n",
    "                mnist=(mnist_train, mnist_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_specific_kwargs = dict(svhn=dict(y_dim=svhn_train.shape[0]), \n",
    "                            #cifar10=dict(y_dim=cifar10_train.shape[0]), \n",
    "                            celeba=dict(y_dim=celeba_train.shape[0]),\n",
    "                            mnist=dict(y_dim=mnist_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 2  # 2D spatial input \n",
    "#Y_DIM = data.shape[0]\n",
    "N_TARGETS = None#data.n_classes\n",
    "\n",
    "#label_percentages = [N_TARGETS, N_TARGETS*2, 0.01, 0.05, 0.1, 0.3, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skssl.transformers import AttentiveNeuralProcess, NeuralProcessLoss, GridConvNeuralProcess, GridNeuralProcessLoss\n",
    "from skssl.predefined import UnetCNN, CNN, SelfAttention, MLP, SelfAttention, SinusoidalEncodings, merge_flat_input\n",
    "from skssl.transformers.neuralproc.datasplit import precomputed_cntxt_trgt_split\n",
    "\n",
    "models_general = {}\n",
    "models_grided = {}\n",
    "\n",
    "anp_kwargs = dict(r_dim=128, \n",
    "                  get_cntxt_trgt=precomputed_cntxt_trgt_split,\n",
    "                  attention=\"transformer\",\n",
    "                  encoded_path=\"deterministic\",\n",
    "                  XYEncoder=merge_flat_input(SelfAttention, is_sum_merge=True),\n",
    "                  output_range=(0,1))\n",
    "\n",
    "\n",
    "unet = partial(UnetCNN,\n",
    "               Conv=torch.nn.Conv2d,\n",
    "               Pool=torch.nn.MaxPool2d,\n",
    "               upsample_mode=\"bilinear\",\n",
    "               n_layers=14,\n",
    "               is_double_conv=True,\n",
    "               is_depth_separable=True,\n",
    "               Normalization=torch.nn.BatchNorm2d,\n",
    "               is_chan_last=True,\n",
    "               bottleneck=None,\n",
    "               kernel_size=7,\n",
    "               max_nchannels=256,\n",
    "               is_force_same_bottleneck=True,\n",
    "               _is_summary=True,\n",
    "              )\n",
    "\n",
    "\n",
    "gnp_kwargs = dict(r_dim=32,\n",
    "                  output_range=(0,1),\n",
    "                  is_normalize=True,\n",
    "                  TmpSelfAttn=unet)\n",
    "\n",
    "gnp_large_kwargs = dict(r_dim=64,\n",
    "                  output_range=(0,1),\n",
    "                  is_normalize=True,\n",
    "                  TmpSelfAttn=partial(unet, n_layers=18))\n",
    "\n",
    "# initialize one model for each dataset\n",
    "models_general[\"anp_simple\"] = partial(AttentiveNeuralProcess, x_dim=X_DIM, **anp_kwargs)\n",
    "#models_grided[\"transformer_gnp_unet\"] = partial(GridConvNeuralProcess, **gnp_kwargs)\n",
    "models_grided[\"transformer_gnp_large_unet\"] = partial(GridConvNeuralProcess, **gnp_large_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anp_simple - N Param: 314150\n",
      "transformer_gnp_large_unet - N Param: 1188615\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import count_parameters\n",
    "for k,v in models_general.items():\n",
    "    print(k, \"- N Param:\", count_parameters(v(y_dim=3)))\n",
    "    \n",
    "for k,v in models_grided.items():\n",
    "    print(k, \"- N Param:\", count_parameters(v(y_dim=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100 \n",
    "BATCH_SIZE = 32\n",
    "IS_RETRAIN = False # if false load precomputed\n",
    "chckpnt_dirname=\"results/notebooks/neural_process_images/\"\n",
    "\n",
    "from ntbks_helpers import train_models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading svhn/transformer_gnp_large_unet ---\n",
      "\n",
      "svhn/transformer_gnp_large_unet best epoch: 6 val_loss: -3.949710527958134\n",
      "\n",
      "--- Loading celeba/transformer_gnp_large_unet ---\n",
      "\n",
      "celeba/transformer_gnp_large_unet best epoch: 5 val_loss: -3.655739565074503\n",
      "\n",
      "--- Loading mnist/transformer_gnp_large_unet ---\n",
      "\n",
      "mnist/transformer_gnp_large_unet best epoch: 9 val_loss: -1.2522213287353516\n"
     ]
    }
   ],
   "source": [
    "data_trainers_grided = {}\n",
    "data_trainers_grided.update(train_models_(datasets,#{k:v for k,v in datasets.items() if k ==\"celeba\"}, \n",
    "                       models_grided, # #\n",
    "                        GridNeuralProcessLoss,\n",
    "                      data_specific_kwargs=data_specific_kwargs,\n",
    "                     patience=15,\n",
    "                     chckpnt_dirname=chckpnt_dirname,\n",
    "                      max_epochs=N_EPOCHS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      is_retrain=IS_RETRAIN,\n",
    "                      callbacks=[],\n",
    "                      iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, is_grided=True, is_repeat_batch=True),  \n",
    "                      iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_test, is_grided=True),\n",
    "                      mode=\"transformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading svhn/anp_simple ---\n",
      "\n",
      "svhn/anp_simple best epoch: 8 val_loss: -3.9245849417702288\n",
      "\n",
      "--- Loading mnist/anp_simple ---\n",
      "\n",
      "mnist/anp_simple best epoch: 1 val_loss: -0.976733584690094\n"
     ]
    }
   ],
   "source": [
    "data_trainers_general = train_models_({k:v for k,v in datasets.items() if k in [\"mnist\", \"svhn\"]}, \n",
    "                      models_general,\n",
    "                      NeuralProcessLoss,\n",
    "                      data_specific_kwargs=data_specific_kwargs,\n",
    "                      patience=15,\n",
    "                      chckpnt_dirname= chckpnt_dirname,\n",
    "                      max_epochs=N_EPOCHS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      is_retrain=IS_RETRAIN,\n",
    "                      callbacks=[],\n",
    "                      iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt),\n",
    "                      iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt_test),\n",
    "                      mode=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svhn/transformer_gnp_large_unet epoch: 6 val_loss: -3.949710527958134 time: 408.01508768399555\n",
      "\n",
      "celeba/transformer_gnp_large_unet epoch: 5 val_loss: -3.655739565074503 time: 2586.62450633049\n",
      "\n",
      "mnist/transformer_gnp_large_unet epoch: 9 val_loss: -1.2522213287353516 time: 227.30238803227743\n"
     ]
    }
   ],
   "source": [
    "for k,t in data_trainers_grided.items():\n",
    "    print()\n",
    "    l=[h[\"dur\"] for h in t.history]\n",
    "    for e, h in enumerate(t.history[::-1]):\n",
    "        if h[\"valid_loss_best\"]:\n",
    "            print(k, \"epoch:\", len(t.history)-e, \n",
    "                  \"val_loss:\", h[\"valid_loss\"],\n",
    "                 \"time:\",  sum(l)/len(l))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svhn/anp_simple epoch: 8 val_loss: -3.9245849417702288 time: 232.7366533279419\n",
      "\n",
      "mnist/anp_simple epoch: 1 val_loss: -0.976733584690094 time: 148.16162109375\n"
     ]
    }
   ],
   "source": [
    "for k,t in data_trainers_general.items():\n",
    "    print()\n",
    "    for e, h in enumerate(t.history[::-1]):\n",
    "        if h[\"valid_loss_best\"]:\n",
    "            print(k, \"epoch:\", len(t.history)-e, \n",
    "                  \"val_loss:\", h[\"valid_loss\"],\n",
    "                 \"time:\", h[\"dur\"])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run svhn + on anp smaal\n",
    "- make tables\n",
    "- test memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
